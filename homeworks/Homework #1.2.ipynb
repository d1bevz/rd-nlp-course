{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа 1. Задание 2\n",
    "\n",
    "1. Используйте датасет fetch_20newsgroups из sklearn.datasets\n",
    "\n",
    "2. Сравните разные bag of words подходы (CountVectorizer, TfidfVectorizer) с перебором гиперпараметров, используя логистическую регрессию (гиперпараметры которой нужно подобрать)\n",
    "\n",
    "3. Реализуйте аналогичное сравнение, но используя алгоритмы на основе бустинга xgboost, lightgbm и catboost\n",
    "\n",
    "4. Прикрепите ссылку на ваш гитхаб с решением в строке комментариев под домашним заданием\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "import numpy as np \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups()\n",
    "test = fetch_20newsgroups(subset=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение bag-of-words подходов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbevz/opt/anaconda3/envs/r_d/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8642383845235152,\n",
       " Pipeline(steps=[('bow', CountVectorizer()), ('clf', LogisticRegression(C=1))]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "params = dict(clf__C=[10, 1, 0.1, 0.01])\n",
    "grid_search = GridSearchCV(pipeline, params, scoring=\"accuracy\", cv=skf, n_jobs=-1)\n",
    "grid_search.fit(train[\"data\"], train[\"target\"], )\n",
    "grid_search.best_score_, grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_names'][grid_search.predict(['This match was great, they scored 3 goals'])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbevz/opt/anaconda3/envs/r_d/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9079011664524309,\n",
       " Pipeline(steps=[('bow', CountVectorizer()), ('clf', LogisticRegression(C=1))]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('bow', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "params = dict(clf__C=[10, 1, 0.1, 0.01])\n",
    "grid_search2 = GridSearchCV(pipeline2, params, scoring=\"accuracy\", cv=skf, n_jobs=-1)\n",
    "grid_search2.fit(train[\"data\"], train[\"target\"], )\n",
    "grid_search2.best_score_, grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.hockey'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target_names'][grid_search2.predict(['This match was great, they scored 3 goals'])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score улучшился, и пример стал классифицироваться более правильно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритмы бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "+ Without stop words\n",
    "+ Log regression vs softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7696667250647464,\n",
       " Pipeline(steps=[('bow',\n",
       "                  TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                              'our', 'ours', 'ourselves', 'you',\n",
       "                                              \"you're\", \"you've\", \"you'll\",\n",
       "                                              \"you'd\", 'your', 'yours',\n",
       "                                              'yourself', 'yourselves', 'he',\n",
       "                                              'him', 'his', 'himself', 'she',\n",
       "                                              \"she's\", 'her', 'hers', 'herself',\n",
       "                                              'it', \"it's\", 'its', 'itself', ...])),\n",
       "                 ('clf',\n",
       "                  XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                colsample_bylev...\n",
       "                                interaction_constraints='', learning_rate=0.1,\n",
       "                                max_delta_step=0, max_depth=12,\n",
       "                                min_child_weight=1, missing=nan,\n",
       "                                monotone_constraints='()', n_estimators=16,\n",
       "                                n_jobs=12, num_parallel_tree=1,\n",
       "                                objective='multi:softprob', random_state=0,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                                subsample=1, tree_method='exact',\n",
       "                                use_label_encoder=False, validate_parameters=1,\n",
       "                                verbosity=None))]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline3 = Pipeline([\n",
    "    ('bow', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False)),\n",
    "])\n",
    "# Parameters for xgboost algorith\n",
    "xgb_params = {\n",
    "    'clf__n_estimators': [16],\n",
    "    'clf__max_depth': [8, 12], # Maximum depth of a tree\n",
    "    'clf__learning_rate': [0.1], \n",
    "    'clf__objective': ['reg:logistic', 'multi:softmax'], \n",
    "    'clf__eval_metric': ['auc']\n",
    "    #'num_class':n_classes\n",
    "}\n",
    "grid_search3 = GridSearchCV(pipeline3, xgb_params, scoring=\"accuracy\", cv=skf, n_jobs=-1)\n",
    "grid_search3.fit(train[\"data\"], train[\"target\"], )\n",
    "grid_search3.best_score_, grid_search3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213223579394583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['target'], grid_search3.predict(test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.65       319\n",
      "           1       0.60      0.65      0.63       389\n",
      "           2       0.66      0.69      0.67       394\n",
      "           3       0.59      0.68      0.63       392\n",
      "           4       0.69      0.73      0.71       385\n",
      "           5       0.74      0.64      0.69       395\n",
      "           6       0.74      0.84      0.79       390\n",
      "           7       0.80      0.73      0.77       396\n",
      "           8       0.86      0.85      0.86       398\n",
      "           9       0.82      0.83      0.83       397\n",
      "          10       0.86      0.85      0.85       399\n",
      "          11       0.88      0.82      0.85       396\n",
      "          12       0.41      0.56      0.47       393\n",
      "          13       0.84      0.68      0.75       396\n",
      "          14       0.82      0.77      0.79       394\n",
      "          15       0.78      0.85      0.82       398\n",
      "          16       0.62      0.78      0.69       364\n",
      "          17       0.92      0.76      0.83       376\n",
      "          18       0.64      0.48      0.55       310\n",
      "          19       0.53      0.49      0.51       251\n",
      "\n",
      "    accuracy                           0.72      7532\n",
      "   macro avg       0.73      0.71      0.72      7532\n",
      "weighted avg       0.73      0.72      0.72      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['target'], grid_search3.predict(test['data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8450592787377841,\n",
       " Pipeline(steps=[('bow',\n",
       "                  TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                              'our', 'ours', 'ourselves', 'you',\n",
       "                                              \"you're\", \"you've\", \"you'll\",\n",
       "                                              \"you'd\", 'your', 'yours',\n",
       "                                              'yourself', 'yourselves', 'he',\n",
       "                                              'him', 'his', 'himself', 'she',\n",
       "                                              \"she's\", 'her', 'hers', 'herself',\n",
       "                                              'it', \"it's\", 'its', 'itself', ...])),\n",
       "                 ('clf', LGBMClassifier())]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline4 = Pipeline([\n",
    "    ('bow', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', LGBMClassifier()),\n",
    "])\n",
    "\n",
    "lgbm_params = dict(\n",
    "    #using default values\n",
    ")\n",
    "\n",
    "grid_search4 = GridSearchCV(pipeline4, lgbm_params, scoring=\"accuracy\", cv=skf, n_jobs=-1)\n",
    "grid_search4.fit(train[\"data\"], train[\"target\"], )\n",
    "grid_search4.best_score_, grid_search4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883696229421137"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['target'], grid_search4.predict(test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       319\n",
      "           1       0.64      0.74      0.69       389\n",
      "           2       0.74      0.75      0.75       394\n",
      "           3       0.61      0.72      0.66       392\n",
      "           4       0.77      0.80      0.78       385\n",
      "           5       0.83      0.70      0.76       395\n",
      "           6       0.83      0.89      0.86       390\n",
      "           7       0.83      0.82      0.82       396\n",
      "           8       0.91      0.87      0.89       398\n",
      "           9       0.89      0.89      0.89       397\n",
      "          10       0.97      0.91      0.94       399\n",
      "          11       0.93      0.87      0.90       396\n",
      "          12       0.56      0.70      0.62       393\n",
      "          13       0.82      0.78      0.80       396\n",
      "          14       0.88      0.88      0.88       394\n",
      "          15       0.89      0.91      0.90       398\n",
      "          16       0.67      0.85      0.75       364\n",
      "          17       0.97      0.73      0.84       376\n",
      "          18       0.72      0.55      0.62       310\n",
      "          19       0.64      0.59      0.62       251\n",
      "\n",
      "    accuracy                           0.79      7532\n",
      "   macro avg       0.79      0.78      0.78      7532\n",
      "weighted avg       0.80      0.79      0.79      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['target'], grid_search4.predict(test['data'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# https://catboost.ai/docs/concepts/python-reference_catboostclassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7cbc937723b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline5 = Pipeline([\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'bow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nlp_course/rd-nlp-course/rd/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterations, learning_rate, depth, l2_leaf_reg, rsm, loss_function, border, border_count, feature_border_type, fold_permutation_block_size, auto_stop_pval, gradient_iterations, leaf_estimation_method, thread_count, random_seed, use_best_model, verbose, ctr_description, ctr_border_count, ctr_leaf_count_limit, store_all_simple_ctr, max_ctr_complexity, priors, has_time, classes_count, class_weights, one_hot_max_size, random_strength, name, ignored_features, train_dir, custom_loss, eval_metric, bagging_temperature, save_snapshot, snapshot_file, fold_len_multiplier, used_ram_limit, feature_priors, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnot_params\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nlp_course/rd-nlp-course/rd/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, model_file)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCatBoost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "pipeline5 = Pipeline([\n",
    "    ('bow', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', CatBoostClassifier()),\n",
    "])\n",
    "\n",
    "cat_params = dict(\n",
    "    clf__loss_function=['MultiClass'],\n",
    "    clf__iterations=[100],\n",
    "    clf__learning_rate=[0.1],\n",
    "    clf__l2_leaf_reg=[3.0],\n",
    "    clf__depth=[10],\n",
    "    \n",
    ")\n",
    "\n",
    "grid_search4 = GridSearchCV(pipeline5, cat_params, scoring=\"accuracy\", cv=skf, n_jobs=-1)\n",
    "grid_search4.fit(train[\"data\"], train[\"target\"], )\n",
    "grid_search4.best_score_, grid_search5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
